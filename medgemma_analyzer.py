#!/usr/bin/env python3
"""
MedGemma Analyzer - Google's Medical AI Model Integration
Provides direct medical image analysis using MedGemma model
"""

import os
import sys
import torch
import time
from typing import List, Dict, Any, Optional
from transformers import AutoProcessor, AutoModelForImageTextToText
from PIL import Image
import config
from progress_logger import (
    show_step, show_success, show_error, show_info, show_warning, 
    start_progress, update_progress, complete_progress, 
    log_to_file, suppress_prints
)

# Check if MedGemma is available
try:
    from transformers import AutoProcessor, AutoModelForImageTextToText
    MEDGEMMA_AVAILABLE = True
    log_to_file("MedGemma dependencies available")
except ImportError as e:
    MEDGEMMA_AVAILABLE = False
    log_to_file(f"MedGemma –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}", "WARNING")

class MedGemmaAnalyzer:
    """Medical image analysis using Google's MedGemma model"""
    
    def __init__(self):
        """Initialize MedGemma analyzer"""
        if not MEDGEMMA_AVAILABLE:
            show_error("MedGemma –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            return
            
        try:
            show_step("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MedGemma –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞")
            self.model_name = "google/medgemma-4b-it"
            self.device = self._get_device()
            self.processor = None
            self.model = None
            self.token = None
            self._load_model()
            show_success("MedGemma –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            show_error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MedGemma: {e}")
            log_to_file(f"MedGemma initialization error: {e}", "ERROR")
            raise
    
    def analyze_study(self, images: List[Dict[str, Any]], user_context: str = "") -> Optional[str]:
        """
        Analyze CT study using MedGemma
        
        Args:
            images: List of processed image data
            user_context: Additional context from user
            
        Returns:
            Medical analysis text
        """
        if not images:
            show_error("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return None
            
        show_step(f"–ó–∞–ø—É—Å–∫ MedGemma –∞–Ω–∞–ª–∏–∑–∞ ({len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
        log_to_file(f"Starting MedGemma analysis with {len(images)} images")
        
        if user_context:
            show_info(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {user_context}")
        
        try:
            # Analyze all images with progress tracking
            result = self._analyze_ct_study(images, user_context)
            
            if result:
                show_success("MedGemma –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ")
                log_to_file("MedGemma analysis completed successfully")
                return result
            else:
                show_warning("MedGemma –∞–Ω–∞–ª–∏–∑ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                log_to_file("MedGemma analysis returned no results", "WARNING")
                return None
                
        except Exception as e:
            show_error(f"–û—à–∏–±–∫–∞ MedGemma –∞–Ω–∞–ª–∏–∑–∞: {e}")
            log_to_file(f"MedGemma analysis error: {e}", "ERROR")
            return None
    
    def _get_device(self):
        """Get the device for model loading"""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def _setup_huggingface_token(self):
        """Setup Hugging Face token"""
        from dotenv import load_dotenv
        from huggingface_hub import login
        load_dotenv()
        
        self.token = os.getenv("HUGGINGFACE_TOKEN")
        if self.token:
            show_success("‚úÖ –¢–æ–∫–µ–Ω Hugging Face –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            log_to_file("Hugging Face token found in .env file")
            show_info(f"üîë –¢–æ–∫–µ–Ω –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å: {self.token[:10]}...")
            log_to_file(f"Token starts with: {self.token[:10]}...")
            
            # –Ø–≤–Ω–∞—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ HuggingFace Hub
            try:
                login(token=self.token, add_to_git_credential=False)
                show_success("‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ HuggingFace Hub —É—Å–ø–µ—à–Ω–∞")
                log_to_file("HuggingFace Hub authentication successful")
            except Exception as e:
                show_error(f"‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ HuggingFace Hub: {e}")
                log_to_file(f"HuggingFace Hub authentication error: {e}", "ERROR")
                raise
        else:
            show_error("‚ùå –¢–æ–∫–µ–Ω Hugging Face –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
            show_info("üí° –î–æ–±–∞–≤—å—Ç–µ HUGGINGFACE_TOKEN=your_token –≤ .env —Ñ–∞–π–ª")
            log_to_file("Hugging Face token not found in .env file", "ERROR")
            raise ValueError("–¢–æ–∫–µ–Ω Hugging Face –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MedGemma")
    
    def _load_model(self):
        """Load the MedGemma model and processor"""
        try:
            show_step("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ MedGemma")
            
            # Setup HuggingFace token
            self._setup_huggingface_token()
            
            # Load processor and model with token
            self.processor = AutoProcessor.from_pretrained(
                self.model_name,
                token=self.token,
                trust_remote_code=True
            )
            self.model = AutoModelForImageTextToText.from_pretrained(
                self.model_name,
                token=self.token,
                torch_dtype=torch.bfloat16 if self.device != "cpu" else torch.float32,
                device_map="auto" if self.device != "cpu" else None,
                trust_remote_code=True
            )
            
            if self.device == "cpu":
                self.model.to(self.device)
            
            show_success("–ú–æ–¥–µ–ª—å MedGemma –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            show_error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ MedGemma: {e}")
            log_to_file(f"Model loading error: {e}", "ERROR")
            raise
    
    def _analyze_ct_study(self, images: List[Dict[str, Any]], user_context: str = "") -> Optional[str]:
        """
        Analyze a single CT image using MedGemma
        
        Args:
            image_data: Dictionary containing 'image' (PIL Image) and 'dicom_data' (DICOM data)
            user_context: Additional context from user
            
        Returns:
            Medical analysis text for the image
        """
        if not self.model or not self.processor:
            show_error("–ú–æ–¥–µ–ª—å MedGemma –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return None
            
        show_step(f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {images[0]['dicom_data']['SeriesInstanceUID']}")
        
        try:
            # Prepare image for MedGemma
            image_data = images[0]
            image = Image.fromarray(image_data['image'])
            
            # Process image
            inputs = self.processor(image, return_tensors="pt").to(self.device)
            
            # Generate text using MedGemma
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=1000,
                    num_beams=5,
                    temperature=0.3
                )
            
            # Decode the generated text
            generated_text = self.processor.decode(outputs[0], skip_special_tokens=True)
            
            # Add user context to the analysis
            if user_context:
                generated_text += f"\n\n–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {user_context}"
            
            show_success(f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à—ë–Ω: {generated_text}")
            return generated_text
            
        except Exception as e:
            show_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            log_to_file(f"Image analysis error: {e}", "ERROR")
            return None
    
    def _create_final_report(self, analyses: List[str]) -> str:
        """–°–æ–∑–¥–∞—ë—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á—ë—Ç"""
        
        report = f"""
=== MEDGEMMA –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ê–ù–ê–õ–ò–ó CT –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø ===

–î–ê–¢–ê –ê–ù–ê–õ–ò–ó–ê: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
–ö–û–õ–ò–ß–ï–°–¢–í–û –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô: {len(analyses)}
–ê–ù–ê–õ–ò–ó–ê–¢–û–†: MedGemma 4B (Google)

=== –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–ú ===

"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã
        for analysis in analyses:
            report += analysis + "\n\n"
        
        # –°–æ–∑–¥–∞—ë–º –æ–±—â–µ–µ —Ä–µ–∑—é–º–µ —Å –ø–æ–º–æ—â—å—é MedGemma
        if self.use_medgemma:
            try:
                summary_prompt = f"""Based on the following CT study analysis, provide a comprehensive summary:

{chr(10).join(analyses)}

Please provide:
1. OVERALL FINDINGS SUMMARY
2. KEY PATHOLOGICAL FINDINGS
3. CLINICAL SIGNIFICANCE
4. RECOMMENDATIONS
5. FOLLOW-UP SUGGESTIONS

Focus on the most clinically relevant findings and provide actionable recommendations."""
                
                summary = self.medgemma_client.analyze_medical_text(
                    summary_prompt,
                    "CT study comprehensive summary"
                )
                
                if summary:
                    report += f"""
=== –û–ë–©–ï–ï –†–ï–ó–Æ–ú–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø (MedGemma) ===

{summary}

=== –ö–û–ù–ï–¶ –û–¢–ß–Å–¢–ê ==="""
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑—é–º–µ: {e}")
                report += "\n=== –ö–û–ù–ï–¶ –û–¢–ß–Å–¢–ê ==="
        
        return report


def test_medgemma_analyzer():
    """–¢–µ—Å—Ç MedGemma –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    print("üß™ –¢–ï–°–¢ MEDGEMMA –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê")
    print("=" * 50)
    
    try:
        from image_processor import ImageProcessor
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if not os.path.exists("input"):
            print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è 'input' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_processor = ImageProcessor()
        images = image_processor.load_dicom_series("input")
        
        if not images:
            print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ 2 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        test_images = images[:2]
        print(f"üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(test_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = MedGemmaAnalyzer()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        result = analyzer.analyze_images(test_images)
        
        if result:
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìÑ –î–ª–∏–Ω–∞ –æ—Ç—á—ë—Ç–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üîç –ü–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤:")
            print(result[:300] + "...")
        else:
            print("‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_medgemma_analyzer() 