"""
Comprehensive CT Analysis System
Analyzes ALL images in a study with context preservation
"""

import os
import json
import requests
from datetime import datetime
from typing import List, Dict, Any, Optional
import base64
from med42_client import Med42Client

# –ü–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å MedGemma, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
try:
    from medgemma_client import MedGemmaClient
    MEDGEMMA_AVAILABLE = True
    print("‚úÖ MedGemma –∫–ª–∏–µ–Ω—Ç –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError as e:
    MEDGEMMA_AVAILABLE = False
    print(f"‚ö†Ô∏è MedGemma –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")


class ComprehensiveAnalyzer:
    """Analyzer that processes ALL images with context preservation"""
    
    def __init__(self):
        self.base_url = "http://localhost:11434"
        self.gemma_model = "gemma3:4b"  # –†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å
        self.vision_model = "llama3.2-vision:latest"  # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MedGemma –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        if MEDGEMMA_AVAILABLE:
            try:
                self.medgemma_client = MedGemmaClient()
                print("‚úÖ MedGemma –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                self.use_medgemma = True
            except Exception as e:
                print(f"‚ö†Ô∏è MedGemma –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
                self.medgemma_client = None
                self.use_medgemma = False
        else:
            self.medgemma_client = None
            self.use_medgemma = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Med42 –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        try:
            self.med42_client = Med42Client()
            print("‚úÖ Med42 –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è Med42 –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            self.med42_client = None
            
        self.context_file = None
        self.session_id = None
        
    def analyze_study(self, images: List[Dict[str, Any]], user_context: str = "") -> Optional[Dict[str, Any]]:
        """
        Analyze CT study with optional user context
        
        Args:
            images: List of processed image data
            user_context: Additional context from user (symptoms, age, etc.)
            
        Returns:
            Comprehensive analysis results
        """
        print(f"üîç Comprehensive –∞–Ω–∞–ª–∏–∑ CT –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ({len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
        
        if user_context:
            print(f"üìù –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {user_context}")
        
        try:
            # Use the comprehensive analysis method with user context
            result = self.analyze_complete_study(images, mode="comprehensive", user_context=user_context)
            
            if result:
                print("‚úÖ Comprehensive –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
                return result
            else:
                print("‚ùå Comprehensive –∞–Ω–∞–ª–∏–∑ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Comprehensive –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None
        
    def analyze_complete_study(self, images: List[Dict[str, Any]], 
                             mode: str = "comprehensive", user_context: str = "") -> Dict[str, Any]:
        """Analyze ALL images in the study with context preservation"""
        
        # Initialize session
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.context_file = f"context/session_{self.session_id}.json"
        
        # Create context directory
        os.makedirs("context", exist_ok=True)
        
        print(f"\nüîç –ù–ê–ß–ò–ù–ê–ï–ú –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø")
        print(f"üìä –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")
        print(f"üóÇÔ∏è  –°–µ—Å—Å–∏—è: {self.session_id}")
        print(f"üíæ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤: {self.context_file}")
        
        # Initialize context
        context = {
            "session_id": self.session_id,
            "start_time": datetime.now().isoformat(),
            "total_images": len(images),
            "mode": mode,
            "user_context": user_context,  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            "progress": {
                "processed": 0,
                "current_batch": 0,
                "total_batches": (len(images) + 9) // 10  # 10 images per batch
            },
            "findings": {
                "anatomical_regions": {},
                "pathological_findings": [],
                "normal_findings": [],
                "organ_assessments": {},
                "cumulative_context": ""
            },
            "image_analyses": []
        }
        
        self._save_context(context)
        
        try:
            # Process images in batches of 10 to maintain context
            batch_size = 10
            total_batches = (len(images) + batch_size - 1) // batch_size
            
            for batch_idx in range(total_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(images))
                batch_images = images[start_idx:end_idx]
                
                print(f"\nüì¶ –û–ë–†–ê–ë–û–¢–ö–ê –ü–ê–ö–ï–¢–ê {batch_idx + 1}/{total_batches}")
                print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {start_idx + 1}-{end_idx} –∏–∑ {len(images)}")
                
                # Process batch
                batch_results = self._process_batch(batch_images, batch_idx, context)
                
                # Update context
                context["progress"]["current_batch"] = batch_idx + 1
                context["progress"]["processed"] = end_idx
                context["image_analyses"].extend(batch_results["individual_analyses"])
                
                # Merge findings
                self._merge_findings(context["findings"], batch_results["batch_summary"])
                
                # Update cumulative context
                context["findings"]["cumulative_context"] = self._update_cumulative_context(
                    context["findings"]["cumulative_context"], 
                    batch_results["batch_summary"]
                )
                
                # Save progress
                self._save_context(context)
                
                print(f"‚úÖ –ü–∞–∫–µ—Ç {batch_idx + 1} –∑–∞–≤–µ—Ä—à—ë–Ω")
                print(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {end_idx}/{len(images)} ({(end_idx/len(images)*100):.1f}%)")
            
            # Generate final comprehensive report
            print(f"\nüìã –°–û–ó–î–ê–ù–ò–ï –ò–¢–û–ì–û–í–û–ì–û –û–¢–ß–Å–¢–ê...")
            final_report = self._generate_final_report(context)
            
            context["end_time"] = datetime.now().isoformat()
            context["final_report"] = final_report
            context["status"] = "completed"
            
            self._save_context(context)
            
            print(f"‚úÖ –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù")
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {context['start_time']} - {context['end_time']}")
            print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            print(f"üíæ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {self.context_file}")
            
            return {
                "session_id": self.session_id,
                "total_images": len(images),
                "context_file": self.context_file,
                "final_report": final_report,
                "status": "completed"
            }
            
        except Exception as e:
            print(f"‚ùå –û–®–ò–ë–ö–ê –ê–ù–ê–õ–ò–ó–ê: {e}")
            context["status"] = "error"
            context["error"] = str(e)
            context["end_time"] = datetime.now().isoformat()
            self._save_context(context)
            return None
    
    def _process_batch(self, batch_images: List[Dict[str, Any]], 
                      batch_idx: int, context: Dict[str, Any]) -> Dict[str, Any]:
        """Process a batch of images"""
        
        print(f"   üîç –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–∫–µ—Ç–µ...")
        
        individual_analyses = []
        batch_findings = {
            "anatomical_regions": {},
            "pathological_findings": [],
            "normal_findings": [],
            "organ_assessments": {}
        }
        
        # Analyze each image in the batch
        for idx, image_data in enumerate(batch_images):
            global_idx = batch_idx * 10 + idx + 1
            print(f"      üñºÔ∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {global_idx}: ", end="")
            
            # Get previous context for this analysis
            previous_context = context["findings"]["cumulative_context"]
            
            # Analyze single image
            analysis = self._analyze_single_image_with_context(
                image_data, global_idx, previous_context
            )
            
            if analysis:
                individual_analyses.append({
                    "image_index": global_idx,
                    "analysis": analysis,
                    "timestamp": datetime.now().isoformat()
                })
                
                # Extract findings from this analysis
                self._extract_findings_from_analysis(analysis, batch_findings)
                print("‚úÖ")
            else:
                print("‚ùå")
        
        # Create batch summary
        batch_summary = self._create_batch_summary(batch_findings, batch_idx + 1)
        
        return {
            "individual_analyses": individual_analyses,
            "batch_summary": batch_summary
        }
    
    def _analyze_single_image_with_context(self, image_data: Dict[str, Any], 
                                         image_idx: int, previous_context: str) -> Optional[str]:
        """Analyze single image with previous context using MedGemma + Med42"""
        
        try:
            # –≠–¢–ê–ü 1: –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Ç Vision –º–æ–¥–µ–ª–∏
            vision_prompt = f"""Analyze this CT image #{image_idx} as an experienced radiologist.

PREVIOUS CONTEXT FROM STUDY:
{previous_context if previous_context else "This is the first image in the study."}

Provide detailed visual analysis:
1. Anatomical identification and orientation
2. Organ assessment (size, density, morphology)  
3. Pathological findings detection
4. Relationship to previous findings
5. Image quality and technical factors

Focus on objective visual findings."""
            
            # Vision analysis –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
            payload = {
                "model": self.vision_model,
                "prompt": vision_prompt,
                "images": [image_data['base64_image']],
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 800
                }
            }
            
            response = requests.post(f"{self.base_url}/api/generate", json=payload, timeout=180)
            
            if response.status_code != 200:
                return None
                
            result = response.json()
            vision_analysis = result.get('response', '').strip()
            
            # Log Vision response
            print("=" * 50)
            print(f"üîç –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ LLAMA VISION (–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_idx}):")
            print(vision_analysis)
            print("=" * 50)
            
            # –≠–¢–ê–ü 2: –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é MedGemma (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            medical_analysis = None
            if self.use_medgemma and self.medgemma_client:
                try:
                    medgemma_prompt = f"""CT Image Analysis #{image_idx}

VISUAL FINDINGS:
{vision_analysis}

STUDY CONTEXT:
{previous_context if previous_context else "First image in study"}

Please provide specialized medical interpretation focusing on clinical significance and diagnostic considerations."""
                    
                    medical_analysis = self.medgemma_client.analyze_radiology_finding(
                        vision_analysis, 
                        previous_context
                    )
                    
                    if medical_analysis:
                        print("=" * 50)
                        print(f"üîç –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ MEDGEMMA (–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è {image_idx}):")
                        print(medical_analysis)
                        print("=" * 50)
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ MedGemma –∞–Ω–∞–ª–∏–∑–∞: {e}")
                    medical_analysis = None
            
            # –≠–¢–ê–ü 3: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é Med42 (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            med42_analysis = None
            if self.med42_client:
                med42_prompt = f"""Based on the following CT image analysis, provide additional medical interpretation:

VISUAL ANALYSIS:
{vision_analysis}

{f"MEDGEMMA INTERPRETATION: {medical_analysis}" if medical_analysis else ""}

STUDY CONTEXT:
{previous_context if previous_context else "First image in study"}

ADDITIONAL MEDICAL ANALYSIS REQUIRED:
1. Clinical significance assessment
2. Differential diagnosis considerations  
3. Pathological findings evaluation
4. Recommendations for further evaluation
5. Integration with previous study findings

Provide comprehensive medical interpretation with clinical terminology."""
                
                try:
                    med42_analysis = self.med42_client._generate_analysis(med42_prompt)
                    
                    if med42_analysis:
                        # Log Med42 response
                        print("=" * 50)
                        print(f"üîç –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ MED42 (–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è {image_idx}):")
                        print(med42_analysis)
                        print("=" * 50)
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Med42 –∞–Ω–∞–ª–∏–∑–∞: {e}")
                    med42_analysis = None
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã
            combined_analysis = f"""–í–ò–ó–£–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó (Llama Vision):
{vision_analysis}"""
            
            if medical_analysis:
                combined_analysis += f"""

–ú–ï–î–ò–¶–ò–ù–°–ö–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø (MedGemma):
{medical_analysis}"""
            
            if med42_analysis:
                combined_analysis += f"""

–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ê–ù–ê–õ–ò–ó (Med42):
{med42_analysis}"""
            
            return combined_analysis
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_idx}: {e}")
            return None
    
    def _extract_findings_from_analysis(self, analysis: str, batch_findings: Dict[str, Any]):
        """Extract structured findings from analysis text"""
        
        analysis_lower = analysis.lower()
        
        # Extract anatomical regions
        anatomical_terms = [
            "head", "neck", "chest", "thorax", "abdomen", "pelvis",
            "brain", "lung", "heart", "liver", "kidney", "pancreas"
        ]
        
        for term in anatomical_terms:
            if term in analysis_lower:
                if term not in batch_findings["anatomical_regions"]:
                    batch_findings["anatomical_regions"][term] = []
                batch_findings["anatomical_regions"][term].append(analysis[:200] + "...")
        
        # Extract pathological findings
        pathological_terms = [
            "abnormal", "pathological", "lesion", "mass", "tumor", 
            "enlarged", "thickened", "irregular", "suspicious"
        ]
        
        if any(term in analysis_lower for term in pathological_terms):
            batch_findings["pathological_findings"].append(analysis[:300] + "...")
        else:
            batch_findings["normal_findings"].append(analysis[:200] + "...")
    
    def _create_batch_summary(self, batch_findings: Dict[str, Any], batch_num: int) -> str:
        """Create summary of batch findings"""
        
        summary = f"BATCH {batch_num} SUMMARY:\n"
        summary += f"Anatomical regions: {', '.join(batch_findings['anatomical_regions'].keys())}\n"
        summary += f"Pathological findings: {len(batch_findings['pathological_findings'])}\n"
        summary += f"Normal findings: {len(batch_findings['normal_findings'])}\n"
        
        return summary
    
    def _merge_findings(self, global_findings: Dict[str, Any], batch_summary: str):
        """Merge batch findings into global findings"""
        # This is a simplified merge - in practice, you'd want more sophisticated merging
        pass
    
    def _update_cumulative_context(self, current_context: str, batch_summary: str) -> str:
        """Update cumulative context with new batch summary"""
        
        if not current_context:
            return batch_summary
        
        # Keep context manageable (last 2000 characters)
        new_context = current_context + "\n" + batch_summary
        if len(new_context) > 2000:
            # Keep the most recent context
            new_context = "...[previous context truncated]...\n" + new_context[-1500:]
        
        return new_context
    
    def _generate_final_report(self, context: Dict[str, Any]) -> str:
        """Generate comprehensive final report with detailed analysis"""
        
        findings = context["findings"]
        
        # –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
        report = f"""
=== –ü–û–õ–ù–´–ô –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó CT –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø ===

üìä –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
–°–µ—Å—Å–∏—è: {context['session_id']}
–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞: {context['start_time']}
–î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {context.get('end_time', '–í –ø—Ä–æ—Ü–µ—Å—Å–µ')}
–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {context['total_images']}
–†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞: {context['mode']}

üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:
- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {context['progress']['total_batches']}
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {context['progress']['processed']}
- –£—Å–ø–µ—à–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤: {context['progress']['processed']}
- –û—à–∏–±–æ–∫: {context['total_images'] - context['progress']['processed']}

üè• –ê–ù–ê–¢–û–ú–ò–ß–ï–°–ö–ò–ï –†–ï–ì–ò–û–ù–´:"""
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∞–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏–º —Ä–µ–≥–∏–æ–Ω–∞–º
        anatomical_regions = findings.get('anatomical_regions', {})
        if anatomical_regions:
            for region, descriptions in anatomical_regions.items():
                report += f"\n\n‚Ä¢ {region.upper()}:"
                for i, desc in enumerate(descriptions[:3], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    report += f"\n  {i}. {desc}"
                if len(descriptions) > 3:
                    report += f"\n  ... –∏ –µ—â—ë {len(descriptions) - 3} –Ω–∞—Ö–æ–¥–æ–∫"
        else:
            report += "\n–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã: –ø–µ—á–µ–Ω—å, –ø–æ—á–∫–∏, –∞–±–¥–æ–º–µ–Ω (–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞)"
        
        # –ü–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏
        report += f"\n\nüîç –ü–ê–¢–û–õ–û–ì–ò–ß–ï–°–ö–ò–ï –ù–ê–•–û–î–ö–ò ({len(findings.get('pathological_findings', []))}):"
        pathological_findings = findings.get('pathological_findings', [])
        if pathological_findings:
            for i, finding in enumerate(pathological_findings, 1):
                report += f"\n{i}. {finding}"
        else:
            report += "\n–í –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö —è–≤–Ω—ã—Ö –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ."
        
        # –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
        report += f"\n\n‚úÖ –ù–û–†–ú–ê–õ–¨–ù–´–ï –ù–ê–•–û–î–ö–ò ({len(findings.get('normal_findings', []))}):"
        normal_findings = findings.get('normal_findings', [])
        if normal_findings:
            for i, finding in enumerate(normal_findings[:5], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                report += f"\n{i}. {finding}"
            if len(normal_findings) > 5:
                report += f"\n... –∏ –µ—â—ë {len(normal_findings) - 5} –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –Ω–∞—Ö–æ–¥–æ–∫"
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∞–Ω–∞–ª–∏–∑–æ–≤
        report += f"\n\nüìã –î–ï–¢–ê–õ–¨–ù–´–ô –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô –ö–û–ù–¢–ï–ö–°–¢:"
        cumulative_context = findings.get('cumulative_context', '')
        if cumulative_context:
            # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ —á–∏—Ç–∞–µ–º—ã–µ —Å–µ–∫—Ü–∏–∏
            context_lines = cumulative_context.split('\n')
            current_section = ""
            for line in context_lines:
                if line.strip():
                    if line.startswith('BATCH'):
                        if current_section:
                            report += f"\n\n{current_section}"
                        current_section = f"üì¶ {line}"
                    else:
                        current_section += f"\n{line}"
            if current_section:
                report += f"\n\n{current_section}"
        else:
            report += "\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if 'image_analyses' in context and context['image_analyses']:
            report += f"\n\nüìñ –î–ï–¢–ê–õ–¨–ù–´–ï –ê–ù–ê–õ–ò–ó–´ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:"
            for analysis_data in context['image_analyses']:
                image_idx = analysis_data.get('image_index', 'N/A')
                analysis = analysis_data.get('analysis', '–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω')
                timestamp = analysis_data.get('timestamp', 'N/A')
                
                report += f"\n\n--- –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï {image_idx} ---"
                report += f"\n–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {timestamp}"
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                if len(analysis) > 1500:
                    report += f"\n{analysis[:1500]}...\n[–∞–Ω–∞–ª–∏–∑ —Å–æ–∫—Ä–∞—â—ë–Ω –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏]"
                else:
                    report += f"\n{analysis}"
        else:
            report += f"\n\nüìñ –î–ï–¢–ê–õ–¨–ù–´–ï –ê–ù–ê–õ–ò–ó–´ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:"
            report += f"\n–î–µ—Ç–∞–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏"
        
        # –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report += f"\n\nüè• –ö–õ–ò–ù–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:"
        report += f"\n‚Ä¢ –î–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ {context['progress']['processed']} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"
        report += f"\n‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–π –∫–∞—Ä—Ç–∏–Ω–æ–π"
        report += f"\n‚Ä¢ –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Å–∏–º–ø—Ç–æ–º–æ–≤ –ø–æ–∫–∞–∑–∞–Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞"
        report += f"\n‚Ä¢ –î–ª—è –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è"
        
        report += f"\n\n=== –ö–û–ù–ï–¶ –î–ï–¢–ê–õ–¨–ù–û–ì–û –û–¢–ß–Å–¢–ê ==="
        report += f"\n\n–û—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        report += f"\n–§–∞–π–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {self.context_file}"
        
        return report
    
    def _save_context(self, context: Dict[str, Any]):
        """Save context to file"""
        try:
            with open(self.context_file, 'w', encoding='utf-8') as f:
                json.dump(context, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
    
    def load_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Load previous session context"""
        context_file = f"context/session_{session_id}.json"
        
        if os.path.exists(context_file):
            try:
                with open(context_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–∏: {e}")
        
        return None
    
    def list_sessions(self) -> List[str]:
        """List all available sessions"""
        if not os.path.exists("context"):
            return []
        
        sessions = []
        for filename in os.listdir("context"):
            if filename.startswith("session_") and filename.endswith(".json"):
                session_id = filename[8:-5]  # Remove "session_" and ".json"
                sessions.append(session_id)
        
        return sorted(sessions, reverse=True)  # Most recent first 