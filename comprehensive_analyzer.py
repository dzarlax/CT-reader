"""
Comprehensive CT Analysis System
Analyzes ALL images in a study with context preservation
"""

import os
import json
import requests
from datetime import datetime
from typing import List, Dict, Any, Optional
import base64
from med42_client import Med42Client

# ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ MedGemma, ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°
try:
    from medgemma_client import MedGemmaClient
    MEDGEMMA_AVAILABLE = True
    print("âœ… MedGemma ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")
except ImportError as e:
    MEDGEMMA_AVAILABLE = False
    print(f"âš ï¸ MedGemma Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°: {e}")


class ComprehensiveAnalyzer:
    """Analyzer that processes ALL images with context preservation"""
    
    def __init__(self):
        self.base_url = "http://localhost:11434"
        self.gemma_model = "gemma3:4b"  # Ð ÐµÐ·ÐµÑ€Ð²Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        self.vision_model = "llama3.2-vision:latest"  # Ð”Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ MedGemma ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°
        if MEDGEMMA_AVAILABLE:
            try:
                self.medgemma_client = MedGemmaClient()
                print("âœ… MedGemma ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð´Ð»Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°")
                self.use_medgemma = True
            except Exception as e:
                print(f"âš ï¸ MedGemma Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°: {e}")
                self.medgemma_client = None
                self.use_medgemma = False
        else:
            self.medgemma_client = None
            self.use_medgemma = False
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Med42 Ð´Ð»Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        try:
            self.med42_client = Med42Client()
            print("âœ… Med42 ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð´Ð»Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°")
        except Exception as e:
            print(f"âš ï¸ Med42 Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°: {e}")
            self.med42_client = None
            
        self.context_file = None
        self.session_id = None
        
    def analyze_study(self, images: List[Dict[str, Any]], user_context: str = "") -> Optional[Dict[str, Any]]:
        """
        Analyze CT study with optional user context
        
        Args:
            images: List of processed image data
            user_context: Additional context from user (symptoms, age, etc.)
            
        Returns:
            Comprehensive analysis results
        """
        print(f"ðŸ” Comprehensive Ð°Ð½Ð°Ð»Ð¸Ð· CT Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ ({len(images)} Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹)")
        
        if user_context:
            print(f"ðŸ“ Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {user_context}")
        
        try:
            # Use the comprehensive analysis method with user context
            result = self.analyze_complete_study(images, mode="comprehensive", user_context=user_context)
            
            if result:
                print("âœ… Comprehensive Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½")
                return result
            else:
                print("âŒ Comprehensive Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ðµ Ð´Ð°Ð» Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²")
                return None
                
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Comprehensive Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
            return None
        
    def analyze_complete_study(self, images: List[Dict[str, Any]], 
                             mode: str = "comprehensive", user_context: str = "") -> Dict[str, Any]:
        """Analyze ALL images in the study with context preservation"""
        
        # Initialize session
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.context_file = f"context/session_{self.session_id}.json"
        
        # Create context directory
        os.makedirs("context", exist_ok=True)
        
        print(f"\nðŸ” ÐÐÐ§Ð˜ÐÐÐ•Ðœ ÐŸÐžÐ›ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— Ð˜Ð¡Ð¡Ð›Ð•Ð”ÐžÐ’ÐÐÐ˜Ð¯")
        print(f"ðŸ“Š Ð’ÑÐµÐ³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: {len(images)}")
        print(f"ðŸ—‚ï¸  Ð¡ÐµÑÑÐ¸Ñ: {self.session_id}")
        print(f"ðŸ’¾ ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ÑÑ Ð²: {self.context_file}")
        
        # Initialize context
        context = {
            "session_id": self.session_id,
            "start_time": datetime.now().isoformat(),
            "total_images": len(images),
            "mode": mode,
            "user_context": user_context,  # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
            "progress": {
                "processed": 0,
                "current_batch": 0,
                "total_batches": (len(images) + 9) // 10  # 10 images per batch
            },
            "findings": {
                "anatomical_regions": {},
                "pathological_findings": [],
                "normal_findings": [],
                "organ_assessments": {},
                "cumulative_context": ""
            },
            "image_analyses": []
        }
        
        self._save_context(context)
        
        try:
            # Process images in batches of 10 to maintain context
            batch_size = 10
            total_batches = (len(images) + batch_size - 1) // batch_size
            
            for batch_idx in range(total_batches):
                start_idx = batch_idx * batch_size
                end_idx = min(start_idx + batch_size, len(images))
                batch_images = images[start_idx:end_idx]
                
                print(f"\nðŸ“¦ ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ ÐŸÐÐšÐ•Ð¢Ð {batch_idx + 1}/{total_batches}")
                print(f"   Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ {start_idx + 1}-{end_idx} Ð¸Ð· {len(images)}")
                
                # Process batch
                batch_results = self._process_batch(batch_images, batch_idx, context)
                
                # Update context
                context["progress"]["current_batch"] = batch_idx + 1
                context["progress"]["processed"] = end_idx
                context["image_analyses"].extend(batch_results["individual_analyses"])
                
                # Merge findings
                self._merge_findings(context["findings"], batch_results["batch_summary"])
                
                # Update cumulative context
                context["findings"]["cumulative_context"] = self._update_cumulative_context(
                    context["findings"]["cumulative_context"], 
                    batch_results["batch_summary"]
                )
                
                # Save progress
                self._save_context(context)
                
                print(f"âœ… ÐŸÐ°ÐºÐµÑ‚ {batch_idx + 1} Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½")
                print(f"ðŸ“ˆ ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ: {end_idx}/{len(images)} ({(end_idx/len(images)*100):.1f}%)")
            
            # Generate final comprehensive report
            print(f"\nðŸ“‹ Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• Ð˜Ð¢ÐžÐ“ÐžÐ’ÐžÐ“Ðž ÐžÐ¢Ð§ÐÐ¢Ð...")
            final_report = self._generate_final_report(context)
            
            context["end_time"] = datetime.now().isoformat()
            context["final_report"] = final_report
            context["status"] = "completed"
            
            self._save_context(context)
            
            print(f"âœ… ÐŸÐžÐ›ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— Ð—ÐÐ’Ð•Ð Ð¨ÐÐ")
            print(f"â±ï¸  Ð’Ñ€ÐµÐ¼Ñ: {context['start_time']} - {context['end_time']}")
            print(f"ðŸ“Š ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {len(images)} Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹")
            print(f"ðŸ’¾ ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: {self.context_file}")
            
            return {
                "session_id": self.session_id,
                "total_images": len(images),
                "context_file": self.context_file,
                "final_report": final_report,
                "status": "completed"
            }
            
        except Exception as e:
            print(f"âŒ ÐžÐ¨Ð˜Ð‘ÐšÐ ÐÐÐÐ›Ð˜Ð—Ð: {e}")
            context["status"] = "error"
            context["error"] = str(e)
            context["end_time"] = datetime.now().isoformat()
            self._save_context(context)
            return None
    
    def _process_batch(self, batch_images: List[Dict[str, Any]], 
                      batch_idx: int, context: Dict[str, Any]) -> Dict[str, Any]:
        """Process a batch of images"""
        
        print(f"   ðŸ” ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð² Ð¿Ð°ÐºÐµÑ‚Ðµ...")
        
        individual_analyses = []
        batch_findings = {
            "anatomical_regions": {},
            "pathological_findings": [],
            "normal_findings": [],
            "organ_assessments": {}
        }
        
        # Analyze each image in the batch
        for idx, image_data in enumerate(batch_images):
            global_idx = batch_idx * 10 + idx + 1
            print(f"      ðŸ–¼ï¸  Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ {global_idx}: ", end="")
            
            # Get previous context for this analysis
            previous_context = context["findings"]["cumulative_context"]
            
            # Analyze single image
            analysis = self._analyze_single_image_with_context(
                image_data, global_idx, previous_context
            )
            
            if analysis:
                individual_analyses.append({
                    "image_index": global_idx,
                    "analysis": analysis,
                    "timestamp": datetime.now().isoformat()
                })
                
                # Extract findings from this analysis
                self._extract_findings_from_analysis(analysis, batch_findings)
                print("âœ…")
            else:
                print("âŒ")
        
        # Create batch summary
        batch_summary = self._create_batch_summary(batch_findings, batch_idx + 1)
        
        return {
            "individual_analyses": individual_analyses,
            "batch_summary": batch_summary
        }
    
    def _analyze_single_image_with_context(self, image_data: Dict[str, Any], 
                                         image_idx: int, previous_context: str) -> Optional[str]:
        """Analyze single image with previous context using MedGemma + Med42"""
        
        try:
            # Ð­Ð¢ÐÐŸ 1: ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
            # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¾Ñ‚ Vision Ð¼Ð¾Ð´ÐµÐ»Ð¸
            vision_prompt = f"""Analyze this CT image #{image_idx} as an experienced radiologist.

PREVIOUS CONTEXT FROM STUDY:
{previous_context if previous_context else "This is the first image in the study."}

Provide detailed visual analysis:
1. Anatomical identification and orientation
2. Organ assessment (size, density, morphology)  
3. Pathological findings detection
4. Relationship to previous findings
5. Image quality and technical factors

Focus on objective visual findings."""
            
            # Vision analysis Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ
            payload = {
                "model": self.vision_model,
                "prompt": vision_prompt,
                "images": [image_data['base64_image']],
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "num_predict": 800
                }
            }
            
            response = requests.post(f"{self.base_url}/api/generate", json=payload, timeout=180)
            
            if response.status_code != 200:
                return None
                
            result = response.json()
            vision_analysis = result.get('response', '').strip()
            
            # Log Vision response
            print("=" * 50)
            print(f"ðŸ” ÐŸÐžÐ›ÐÐ«Ð™ ÐžÐ¢Ð’Ð•Ð¢ LLAMA VISION (Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ {image_idx}):")
            print(vision_analysis)
            print("=" * 50)
            
            # Ð­Ð¢ÐÐŸ 2: ÐœÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ MedGemma (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°)
            medical_analysis = None
            if self.use_medgemma and self.medgemma_client:
                try:
                    medgemma_prompt = f"""CT Image Analysis #{image_idx}

VISUAL FINDINGS:
{vision_analysis}

STUDY CONTEXT:
{previous_context if previous_context else "First image in study"}

Please provide specialized medical interpretation focusing on clinical significance and diagnostic considerations."""
                    
                    medical_analysis = self.medgemma_client.analyze_radiology_finding(
                        vision_analysis, 
                        previous_context
                    )
                    
                    if medical_analysis:
                        print("=" * 50)
                        print(f"ðŸ” ÐŸÐžÐ›ÐÐ«Ð™ ÐžÐ¢Ð’Ð•Ð¢ MEDGEMMA (ÐœÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ {image_idx}):")
                        print(medical_analysis)
                        print("=" * 50)
                        
                except Exception as e:
                    print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° MedGemma Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
                    medical_analysis = None
            
            # Ð­Ð¢ÐÐŸ 3: Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Med42 (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°)
            med42_analysis = None
            if self.med42_client:
                med42_prompt = f"""Based on the following CT image analysis, provide additional medical interpretation:

VISUAL ANALYSIS:
{vision_analysis}

{f"MEDGEMMA INTERPRETATION: {medical_analysis}" if medical_analysis else ""}

STUDY CONTEXT:
{previous_context if previous_context else "First image in study"}

ADDITIONAL MEDICAL ANALYSIS REQUIRED:
1. Clinical significance assessment
2. Differential diagnosis considerations  
3. Pathological findings evaluation
4. Recommendations for further evaluation
5. Integration with previous study findings

Provide comprehensive medical interpretation with clinical terminology."""
                
                try:
                    med42_analysis = self.med42_client._generate_analysis(med42_prompt)
                    
                    if med42_analysis:
                        # Log Med42 response
                        print("=" * 50)
                        print(f"ðŸ” ÐŸÐžÐ›ÐÐ«Ð™ ÐžÐ¢Ð’Ð•Ð¢ MED42 (Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ñ {image_idx}):")
                        print(med42_analysis)
                        print("=" * 50)
                        
                except Exception as e:
                    print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Med42 Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
                    med42_analysis = None
            
            # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð²ÑÐµ Ð°Ð½Ð°Ð»Ð¸Ð·Ñ‹
            combined_analysis = f"""Ð’Ð˜Ð—Ð£ÐÐ›Ð¬ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— (Llama Vision):
{vision_analysis}"""
            
            if medical_analysis:
                combined_analysis += f"""

ÐœÐ•Ð”Ð˜Ð¦Ð˜ÐÐ¡ÐšÐÐ¯ Ð˜ÐÐ¢Ð•Ð ÐŸÐ Ð•Ð¢ÐÐ¦Ð˜Ð¯ (MedGemma):
{medical_analysis}"""
            
            if med42_analysis:
                combined_analysis += f"""

Ð”ÐžÐŸÐžÐ›ÐÐ˜Ð¢Ð•Ð›Ð¬ÐÐ«Ð™ ÐœÐ•Ð”Ð˜Ð¦Ð˜ÐÐ¡ÐšÐ˜Ð™ ÐÐÐÐ›Ð˜Ð— (Med42):
{med42_analysis}"""
            
            return combined_analysis
            
        except Exception as e:
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ {image_idx}: {e}")
            return None
    
    def _extract_findings_from_analysis(self, analysis: str, batch_findings: Dict[str, Any]):
        """Extract structured findings from analysis text"""
        
        analysis_lower = analysis.lower()
        
        # Extract anatomical regions
        anatomical_terms = [
            "head", "neck", "chest", "thorax", "abdomen", "pelvis",
            "brain", "lung", "heart", "liver", "kidney", "pancreas"
        ]
        
        for term in anatomical_terms:
            if term in analysis_lower:
                if term not in batch_findings["anatomical_regions"]:
                    batch_findings["anatomical_regions"][term] = []
                batch_findings["anatomical_regions"][term].append(analysis[:200] + "...")
        
        # Extract pathological findings
        pathological_terms = [
            "abnormal", "pathological", "lesion", "mass", "tumor", 
            "enlarged", "thickened", "irregular", "suspicious"
        ]
        
        if any(term in analysis_lower for term in pathological_terms):
            batch_findings["pathological_findings"].append(analysis[:300] + "...")
        else:
            batch_findings["normal_findings"].append(analysis[:200] + "...")
    
    def _create_batch_summary(self, batch_findings: Dict[str, Any], batch_num: int) -> str:
        """Create summary of batch findings"""
        
        summary = f"BATCH {batch_num} SUMMARY:\n"
        summary += f"Anatomical regions: {', '.join(batch_findings['anatomical_regions'].keys())}\n"
        summary += f"Pathological findings: {len(batch_findings['pathological_findings'])}\n"
        summary += f"Normal findings: {len(batch_findings['normal_findings'])}\n"
        
        return summary
    
    def _merge_findings(self, global_findings: Dict[str, Any], batch_summary: str):
        """Merge batch findings into global findings"""
        # This is a simplified merge - in practice, you'd want more sophisticated merging
        pass
    
    def _update_cumulative_context(self, current_context: str, batch_summary: str) -> str:
        """Update cumulative context with new batch summary"""
        
        if not current_context:
            return batch_summary
        
        # Keep context manageable (last 2000 characters)
        new_context = current_context + "\n" + batch_summary
        if len(new_context) > 2000:
            # Keep the most recent context
            new_context = "...[previous context truncated]...\n" + new_context[-1500:]
        
        return new_context
    
    def _generate_final_report(self, context: Dict[str, Any]) -> str:
        """Generate comprehensive final report with detailed analysis"""
        
        findings = context["findings"]
        
        # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚
        report = f"""
=== ÐŸÐžÐ›ÐÐ«Ð™ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— CT Ð˜Ð¡Ð¡Ð›Ð•Ð”ÐžÐ’ÐÐÐ˜Ð¯ ===

ðŸ“Š ÐžÐ‘Ð©ÐÐ¯ Ð˜ÐÐ¤ÐžÐ ÐœÐÐ¦Ð˜Ð¯:
Ð¡ÐµÑÑÐ¸Ñ: {context['session_id']}
Ð”Ð°Ñ‚Ð° Ð½Ð°Ñ‡Ð°Ð»Ð°: {context['start_time']}
Ð”Ð°Ñ‚Ð° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ: {context.get('end_time', 'Ð’ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ')}
Ð’ÑÐµÐ³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: {context['total_images']}
Ð ÐµÐ¶Ð¸Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {context['mode']}

ðŸ“ˆ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐšÐ˜:
- ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²: {context['progress']['total_batches']}
- Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {context['progress']['processed']}
- Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²: {context['progress']['processed']}
- ÐžÑˆÐ¸Ð±Ð¾Ðº: {context['total_images'] - context['progress']['processed']}

ðŸ¥ ÐÐÐÐ¢ÐžÐœÐ˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð Ð•Ð“Ð˜ÐžÐÐ«:"""
        
        # Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¿Ð¾ Ð°Ð½Ð°Ñ‚Ð¾Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°Ð¼
        anatomical_regions = findings.get('anatomical_regions', {})
        if anatomical_regions:
            for region, descriptions in anatomical_regions.items():
                report += f"\n\nâ€¢ {region.upper()}:"
                for i, desc in enumerate(descriptions[:3], 1):  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 3
                    report += f"\n  {i}. {desc}"
                if len(descriptions) > 3:
                    report += f"\n  ... Ð¸ ÐµÑ‰Ñ‘ {len(descriptions) - 3} Ð½Ð°Ñ…Ð¾Ð´Ð¾Ðº"
        else:
            report += "\nÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹: Ð¿ÐµÑ‡ÐµÐ½ÑŒ, Ð¿Ð¾Ñ‡ÐºÐ¸, Ð°Ð±Ð´Ð¾Ð¼ÐµÐ½ (Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°)"
        
        # ÐŸÐ°Ñ‚Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð½Ð°Ñ…Ð¾Ð´ÐºÐ¸
        report += f"\n\nðŸ” ÐŸÐÐ¢ÐžÐ›ÐžÐ“Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• ÐÐÐ¥ÐžÐ”ÐšÐ˜ ({len(findings.get('pathological_findings', []))}):"
        pathological_findings = findings.get('pathological_findings', [])
        if pathological_findings:
            for i, finding in enumerate(pathological_findings, 1):
                report += f"\n{i}. {finding}"
        else:
            report += "\nÐ’ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÑ… ÑÐ²Ð½Ñ‹Ñ… Ð¿Ð°Ñ‚Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ Ð½Ðµ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¾."
        
        # ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð°Ñ…Ð¾Ð´ÐºÐ¸
        report += f"\n\nâœ… ÐÐžÐ ÐœÐÐ›Ð¬ÐÐ«Ð• ÐÐÐ¥ÐžÐ”ÐšÐ˜ ({len(findings.get('normal_findings', []))}):"
        normal_findings = findings.get('normal_findings', [])
        if normal_findings:
            for i, finding in enumerate(normal_findings[:5], 1):  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 5
                report += f"\n{i}. {finding}"
            if len(normal_findings) > 5:
                report += f"\n... Ð¸ ÐµÑ‰Ñ‘ {len(normal_findings) - 5} Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð½Ð°Ñ…Ð¾Ð´Ð¾Ðº"
        
        # Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²
        report += f"\n\nðŸ“‹ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐœÐ•Ð”Ð˜Ð¦Ð˜ÐÐ¡ÐšÐ˜Ð™ ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢:"
        cumulative_context = findings.get('cumulative_context', '')
        if cumulative_context:
            # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ðµ ÑÐµÐºÑ†Ð¸Ð¸
            context_lines = cumulative_context.split('\n')
            current_section = ""
            for line in context_lines:
                if line.strip():
                    if line.startswith('BATCH'):
                        if current_section:
                            report += f"\n\n{current_section}"
                        current_section = f"ðŸ“¦ {line}"
                    else:
                        current_section += f"\n{line}"
            if current_section:
                report += f"\n\n{current_section}"
        else:
            report += "\nÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½"
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²ÑÐµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ñ‹, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ ÐµÑÑ‚ÑŒ
        if 'image_analyses' in context and context['image_analyses']:
            report += f"\n\nðŸ“– Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð• ÐÐÐÐ›Ð˜Ð—Ð« Ð˜Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ˜Ð™:"
            for analysis_data in context['image_analyses']:
                image_idx = analysis_data.get('image_index', 'N/A')
                analysis = analysis_data.get('analysis', 'ÐÐ½Ð°Ð»Ð¸Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½')
                timestamp = analysis_data.get('timestamp', 'N/A')
                
                report += f"\n\n--- Ð˜Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ˜Ð• {image_idx} ---"
                report += f"\nÐ’Ñ€ÐµÐ¼Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {timestamp}"
                
                # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð»Ð¸Ð½Ñƒ Ð´Ð»Ñ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸
                if len(analysis) > 1500:
                    report += f"\n{analysis[:1500]}...\n[Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ¾ÐºÑ€Ð°Ñ‰Ñ‘Ð½ Ð´Ð»Ñ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸]"
                else:
                    report += f"\n{analysis}"
        else:
            report += f"\n\nðŸ“– Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð• ÐÐÐÐ›Ð˜Ð—Ð« Ð˜Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ˜Ð™:"
            report += f"\nÐ”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ñ‹ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ Ð² ÑÑ‚Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸"
        
        # ÐšÐ»Ð¸Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
        report += f"\n\nðŸ¥ ÐšÐ›Ð˜ÐÐ˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜:"
        report += f"\nâ€¢ Ð”Ð°Ð½Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¾ÑÐ½Ð¾Ð²Ð°Ð½ Ð½Ð° {context['progress']['processed']} Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÑ…"
        report += f"\nâ€¢ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ ÐºÐ¾Ñ€Ñ€ÐµÐ»ÑÑ†Ð¸Ñ Ñ ÐºÐ»Ð¸Ð½Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ð¾Ð¹"
        report += f"\nâ€¢ ÐŸÑ€Ð¸ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸ ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ð¾Ð² Ð¿Ð¾ÐºÐ°Ð·Ð°Ð½Ð° ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð°"
        report += f"\nâ€¢ Ð”Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ"
        
        report += f"\n\n=== ÐšÐžÐÐ•Ð¦ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐžÐ“Ðž ÐžÐ¢Ð§ÐÐ¢Ð ==="
        report += f"\n\nÐžÑ‚Ñ‡Ñ‘Ñ‚ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        report += f"\nÐ¤Ð°Ð¹Ð» ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°: {self.context_file}"
        
        return report
    
    def _save_context(self, context: Dict[str, Any]):
        """Save context to file"""
        try:
            with open(self.context_file, 'w', encoding='utf-8') as f:
                json.dump(context, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°: {e}")
    
    def load_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Load previous session context"""
        context_file = f"context/session_{session_id}.json"
        
        if os.path.exists(context_file):
            try:
                with open(context_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÑÐµÑÑÐ¸Ð¸: {e}")
        
        return None
    
    def list_sessions(self) -> List[str]:
        """List all available sessions"""
        if not os.path.exists("context"):
            return []
        
        sessions = []
        for filename in os.listdir("context"):
            if filename.startswith("session_") and filename.endswith(".json"):
                session_id = filename[8:-5]  # Remove "session_" and ".json"
                sessions.append(session_id)
        
        return sorted(sessions, reverse=True)  # Most recent first 