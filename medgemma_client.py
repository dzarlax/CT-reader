#!/usr/bin/env python3
"""
MedGemma Client
–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MedGemma 4B - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –º–æ–¥–µ–ª—å—é –æ—Ç Google
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from PIL import Image
import base64
from io import BytesIO
from typing import Optional, Dict, Any
import logging
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

class MedGemmaClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è MedGemma 4B - –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç Google"""
    
    def __init__(self, model_name: str = "google/medgemma-4b-it"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MedGemma –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face
        """
        self.model_name = model_name
        self.device = self._get_device()
        self.tokenizer = None
        self.model = None
        self.max_length = 4096  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤
        
        print(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MedGemma –∫–ª–∏–µ–Ω—Ç–∞...")
        print(f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–æ–∫–µ–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.token = os.getenv("HUGGINGFACE_TOKEN")
        if self.token:
            print("‚úÖ –¢–æ–∫–µ–Ω Hugging Face –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            print(f"üîë –¢–æ–∫–µ–Ω –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å: {self.token[:10]}...")
        else:
            print("‚ùå –¢–æ–∫–µ–Ω Hugging Face –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
            print("üí° –î–æ–±–∞–≤—å—Ç–µ HUGGINGFACE_TOKEN=your_token –≤ .env —Ñ–∞–π–ª")
            raise ValueError("–¢–æ–∫–µ–Ω Hugging Face –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MedGemma")
        
        self._load_model()
    
    def _get_device(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon GPU
        else:
            return "cpu"
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä"""
        try:
            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ MedGemma –º–æ–¥–µ–ª–∏: {self.model_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                token=self.token,
                trust_remote_code=True
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                token=self.token,
                torch_dtype=torch.float16 if self.device != "cpu" else torch.float32,
                device_map="auto" if self.device != "cpu" else None,
                trust_remote_code=True
            )
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
            
            print(f"‚úÖ MedGemma –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MedGemma: {e}")
            print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
            print("   1. –£ –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ google/medgemma-4b-it")
            print("   2. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è HUGGINGFACE_TOKEN")
            print("   3. –¢–æ–∫–µ–Ω –∏–º–µ–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞")
            raise
    
    def analyze_medical_text(self, text: str, context: str = "") -> Optional[str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é MedGemma
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            
        Returns:
            –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Ç MedGemma
        """
        if not self.model or not self.tokenizer:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            if context:
                prompt = f"""Context: {context}

Medical Analysis Request: {text}

Please provide a detailed medical analysis including:
1. Clinical findings interpretation
2. Differential diagnosis considerations  
3. Recommended follow-up actions
4. Risk assessment

Analysis:"""
            else:
                prompt = f"""Medical Analysis Request: {text}

Please provide a detailed medical analysis including:
1. Clinical findings interpretation
2. Differential diagnosis considerations
3. Recommended follow-up actions  
4. Risk assessment

Analysis:"""
            
            # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º
            inputs = self.tokenizer(
                prompt,
                return_tensors="pt",
                truncation=True,
                max_length=self.max_length - 512  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            ).to(self.device)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=512,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = self.tokenizer.decode(
                outputs[0][inputs['input_ids'].shape[1]:],
                skip_special_tokens=True
            ).strip()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
            print("üîç –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ MEDGEMMA:")
            print("=" * 50)
            print(response)
            print("=" * 50)
            
            return response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ MedGemma: {e}")
            return None
    
    def analyze_radiology_finding(self, finding: str, image_context: str = "") -> Optional[str]:
        """
        –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Ö–æ–¥–æ–∫
        
        Args:
            finding: –†–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –Ω–∞—Ö–æ–¥–∫–∞
            image_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        """
        prompt = f"""Radiology Finding: {finding}

{f"Image Context: {image_context}" if image_context else ""}

As a medical AI assistant specialized in radiology, please provide:

1. CLINICAL SIGNIFICANCE:
   - What does this finding indicate?
   - Severity assessment
   
2. DIFFERENTIAL DIAGNOSIS:
   - Most likely diagnoses
   - Alternative considerations
   
3. FOLLOW-UP RECOMMENDATIONS:
   - Additional imaging needed
   - Clinical correlation required
   - Urgent vs routine follow-up
   
4. PATIENT COUNSELING POINTS:
   - Key information for patient
   - Prognosis considerations"""
        
        return self.analyze_medical_text(prompt)

def test_medgemma():
    """–¢–µ—Å—Ç MedGemma –∫–ª–∏–µ–Ω—Ç–∞"""
    print("üß™ –¢–ï–°–¢ MEDGEMMA –ö–õ–ò–ï–ù–¢–ê")
    print("=" * 40)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç
        client = MedGemmaClient()
        
        # –¢–µ—Å—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        test_finding = "CT –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–∞–≤–æ–π –¥–æ–ª–µ –ø–µ—á–µ–Ω–∏"
        
        print(f"\nüìù –¢–µ—Å—Ç–æ–≤–∞—è –Ω–∞—Ö–æ–¥–∫–∞: {test_finding}")
        result = client.analyze_radiology_finding(test_finding)
        
        if result:
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω (–¥–ª–∏–Ω–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤)")
            print(f"üìÑ –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {result[:200]}...")
        else:
            print("‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ –ø–æ–ª—É—á–µ–Ω")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")

if __name__ == "__main__":
    test_medgemma() 