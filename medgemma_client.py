#!/usr/bin/env python3
"""
MedGemma Client
–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MedGemma 4B - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –º–æ–¥–µ–ª—å—é –æ—Ç Google
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Ç–µ–∫—Å—Ç–∞
"""

import torch
from transformers import AutoProcessor, AutoModelForImageTextToText
from PIL import Image
import base64
from io import BytesIO
from typing import Optional, Dict, Any, List
import logging
import os
from dotenv import load_dotenv
from datetime import datetime

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

class MedGemmaClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è MedGemma 4B - –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç Google —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self, model_name: str = "google/medgemma-4b-it"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MedGemma –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face
        """
        self.model_name = model_name
        self.device = self._get_device()
        self.processor = None
        self.model = None
        
        print(f"üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MedGemma –∫–ª–∏–µ–Ω—Ç–∞...")
        print(f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–æ–∫–µ–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.token = os.getenv("HUGGINGFACE_TOKEN")
        if self.token:
            print("‚úÖ –¢–æ–∫–µ–Ω Hugging Face –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
            print(f"üîë –¢–æ–∫–µ–Ω –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å: {self.token[:10]}...")
        else:
            print("‚ùå –¢–æ–∫–µ–Ω Hugging Face –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
            print("üí° –î–æ–±–∞–≤—å—Ç–µ HUGGINGFACE_TOKEN=your_token –≤ .env —Ñ–∞–π–ª")
            raise ValueError("–¢–æ–∫–µ–Ω Hugging Face –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å MedGemma")
        
        self._load_model()
    
    def _get_device(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"  # Apple Silicon GPU
        else:
            return "cpu"
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä"""
        try:
            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ MedGemma –º–æ–¥–µ–ª–∏: {self.model_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–º
            self.model = AutoModelForImageTextToText.from_pretrained(
                self.model_name,
                token=self.token,
                torch_dtype=torch.bfloat16 if self.device != "cpu" else torch.float32,
                device_map="auto" if self.device != "cpu" else None,
                trust_remote_code=True
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
            self.processor = AutoProcessor.from_pretrained(
                self.model_name,
                token=self.token,
                trust_remote_code=True
            )
            
            if self.device == "cpu":
                self.model = self.model.to(self.device)
            
            print(f"‚úÖ MedGemma –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
            print(f"üîß –ú–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + —Ç–µ–∫—Å—Ç")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MedGemma: {e}")
            print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
            print("   1. –£ –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ google/medgemma-4b-it")
            print("   2. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è HUGGINGFACE_TOKEN")
            print("   3. –¢–æ–∫–µ–Ω –∏–º–µ–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞")
            print("   4. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ accelerate: pip install accelerate")
            raise
    
    def analyze_medical_image(self, image_data: Dict[str, Any], prompt: str = "") -> Optional[str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é —Å –ø–æ–º–æ—â—å—é MedGemma
        
        Args:
            image_data: –î–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å base64_image
            prompt: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        if not self.model or not self.processor:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
        
        try:
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ base64
            image_bytes = base64.b64decode(image_data['base64_image'])
            image = Image.open(BytesIO(image_bytes))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if not prompt:
                prompt = """Analyze this medical CT image and provide a comprehensive medical assessment.

Please provide:

1. VISUAL FINDINGS:
   - Anatomical structures visible
   - Tissue densities and morphology
   - Any abnormal findings or pathology

2. CLINICAL INTERPRETATION:
   - Medical significance of findings
   - Differential diagnosis considerations
   - Severity assessment

3. RECOMMENDATIONS:
   - Additional imaging if needed
   - Clinical correlation required
   - Follow-up suggestions
   - Urgency level

Provide detailed, clinically relevant analysis focused on diagnostic and therapeutic implications."""
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
            messages = [
                {
                    "role": "system",
                    "content": [{"type": "text", "text": "You are an expert radiologist specializing in CT image analysis."}]
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image", "image": image}
                    ]
                }
            ]
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            inputs = self.processor.apply_chat_template(
                messages, 
                add_generation_prompt=True, 
                tokenize=True,
                return_dict=True, 
                return_tensors="pt"
            ).to(self.model.device, dtype=torch.bfloat16 if self.device != "cpu" else torch.float32)
            
            input_len = inputs["input_ids"].shape[-1]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            with torch.inference_mode():
                generation = self.model.generate(
                    **inputs, 
                    max_new_tokens=512,
                    do_sample=False,
                    temperature=0.7 if self.device != "cpu" else 1.0
                )
                generation = generation[0][input_len:]
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = self.processor.decode(generation, skip_special_tokens=True)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
            print("üîç –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ MEDGEMMA (–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è):")
            print("=" * 50)
            print(response)
            print("=" * 50)
            
            return response.strip()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è MedGemma: {e}")
            return None
    
    def analyze_ct_study(self, images: List[Dict[str, Any]], study_context: str = "") -> Optional[str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–µ—Ä–∏—é CT –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–∞–∫ –µ–¥–∏–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
        
        Args:
            images: –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            study_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        """
        if not images:
            return None
        
        print(f"üîç MedGemma –∞–Ω–∞–ª–∏–∑ CT –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è ({len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)...")
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            individual_analyses = []
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            max_images = min(len(images), 5)
            
            for i, image_data in enumerate(images[:max_images], 1):
                print(f"üìä –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i}/{max_images}: ", end="")
                
                slice_prompt = f"""Analyze this CT slice #{i} from a medical study.

{f"Study Context: {study_context}" if study_context else ""}

Please provide:
1. Anatomical structures visible in this slice
2. Any pathological findings
3. Clinical significance of findings
4. Relationship to adjacent slices (if applicable)

Focus on medically relevant observations."""
                
                analysis = self.analyze_medical_image(image_data, slice_prompt)
                
                if analysis:
                    individual_analyses.append(f"=== CT SLICE {i} ===\n{analysis}")
                    print("‚úÖ")
                else:
                    print("‚ùå")
            
            if not individual_analyses:
                return None
            
            # –°–æ–∑–¥–∞—ë–º –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            study_summary = self.analyze_medical_text(
                f"""Based on the following CT study analysis, provide a comprehensive radiology report:

{chr(10).join(individual_analyses)}

Study Context: {study_context}

Please provide a structured radiology report including:

1. TECHNIQUE AND QUALITY
2. FINDINGS BY ANATOMICAL REGION
3. IMPRESSION/CONCLUSION
4. RECOMMENDATIONS

Format as a professional radiology report.""",
                "CT study comprehensive analysis"
            )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            final_report = f"""=== MEDGEMMA CT STUDY ANALYSIS ===

STUDY DETAILS:
- Images analyzed: {len(individual_analyses)} of {len(images)} total
- Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- Model: MedGemma 4B (Google) - Vision + Text
- Analysis method: Direct image analysis

=== INDIVIDUAL SLICE ANALYSES ===

{chr(10).join(individual_analyses)}

=== COMPREHENSIVE STUDY REPORT ===

{study_summary if study_summary else "Summary generation failed"}

=== END OF REPORT ==="""
            
            return final_report
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ CT –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
            return None
    
    def analyze_medical_text(self, text: str, context: str = "") -> Optional[str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é MedGemma
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            
        Returns:
            –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Ç MedGemma
        """
        if not self.model or not self.processor:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            if context:
                prompt = f"""Context: {context}

Medical Analysis Request: {text}

Please provide a detailed medical analysis including:
1. Clinical findings interpretation
2. Differential diagnosis considerations  
3. Recommended follow-up actions
4. Risk assessment

Analysis:"""
            else:
                prompt = f"""Medical Analysis Request: {text}

Please provide a detailed medical analysis including:
1. Clinical findings interpretation
2. Differential diagnosis considerations
3. Recommended follow-up actions  
4. Risk assessment

Analysis:"""
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            messages = [
                {
                    "role": "system",
                    "content": [{"type": "text", "text": "You are an expert medical AI assistant."}]
                },
                {
                    "role": "user",
                    "content": [{"type": "text", "text": prompt}]
                }
            ]
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            inputs = self.processor.apply_chat_template(
                messages, 
                add_generation_prompt=True, 
                tokenize=True,
                return_dict=True, 
                return_tensors="pt"
            ).to(self.model.device, dtype=torch.bfloat16 if self.device != "cpu" else torch.float32)
            
            input_len = inputs["input_ids"].shape[-1]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            with torch.inference_mode():
                generation = self.model.generate(
                    **inputs, 
                    max_new_tokens=512,
                    do_sample=False,
                    temperature=0.7 if self.device != "cpu" else 1.0
                )
                generation = generation[0][input_len:]
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = self.processor.decode(generation, skip_special_tokens=True)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
            print("üîç –ü–û–õ–ù–´–ô –û–¢–í–ï–¢ MEDGEMMA (–¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑):")
            print("=" * 50)
            print(response)
            print("=" * 50)
            
            return response.strip()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ MedGemma: {e}")
            return None
    
    def analyze_radiology_finding(self, finding: str, image_context: str = "") -> Optional[str]:
        """
        –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Ö–æ–¥–æ–∫
        
        Args:
            finding: –†–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –Ω–∞—Ö–æ–¥–∫–∞
            image_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        """
        prompt = f"""Radiology Finding: {finding}

{f"Image Context: {image_context}" if image_context else ""}

As a medical AI assistant specialized in radiology, please provide:

1. CLINICAL SIGNIFICANCE:
   - What does this finding indicate?
   - Severity assessment
   
2. DIFFERENTIAL DIAGNOSIS:
   - Most likely diagnoses
   - Alternative considerations
   
3. FOLLOW-UP RECOMMENDATIONS:
   - Additional imaging needed
   - Clinical correlation required
   - Urgent vs routine follow-up
   
4. PATIENT COUNSELING POINTS:
   - Key information for patient
   - Prognosis considerations"""
        
        return self.analyze_medical_text(prompt)


def test_medgemma():
    """–¢–µ—Å—Ç MedGemma –∫–ª–∏–µ–Ω—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    print("üß™ –¢–ï–°–¢ MEDGEMMA –ö–õ–ò–ï–ù–¢–ê (–° –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–ú–ò)")
    print("=" * 50)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç
        client = MedGemmaClient()
        
        # –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        print("\nüìä –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        
        from image_processor import ImageProcessor
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if not os.path.exists("input"):
            print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è 'input' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_processor = ImageProcessor()
        images = image_processor.load_dicom_series("input")
        
        if not images:
            print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–µ—Ä–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        test_image = images[0]
        print(f"üì∑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {test_image.get('filename', 'unknown')}")
        
        result = client.analyze_medical_image(test_image)
        
        if result:
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—É—á–µ–Ω (–¥–ª–∏–Ω–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤)")
            print(f"üìÑ –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {result[:200]}...")
        else:
            print("‚ùå –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –ø–æ–ª—É—á–µ–Ω")
        
        # –¢–µ—Å—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        print("\nüìù –¢–µ—Å—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        test_finding = "CT –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–∞–≤–æ–π –¥–æ–ª–µ –ø–µ—á–µ–Ω–∏"
        
        text_result = client.analyze_radiology_finding(test_finding)
        
        if text_result:
            print(f"‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω (–¥–ª–∏–Ω–∞: {len(text_result)} —Å–∏–º–≤–æ–ª–æ–≤)")
            print(f"üìÑ –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {text_result[:200]}...")
        else:
            print("‚ùå –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –ø–æ–ª—É—á–µ–Ω")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_medgemma() 